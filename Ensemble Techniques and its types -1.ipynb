{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9192ccb",
   "metadata": {},
   "source": [
    "Q1. What is an ensemble technique in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cce9a0",
   "metadata": {},
   "source": [
    "Ans:-An ensemble technique in machine learning involves combining multiple individual models to improve overall predictive performance. These models could be of the same type (e.g., multiple decision trees) or different types (e.g., a combination of decision trees, neural networks, and support vector machines)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecc8c52",
   "metadata": {},
   "source": [
    "Q2. Why are ensemble techniques used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82470725",
   "metadata": {},
   "source": [
    "Ans:-  Ensemble techniques are used in machine learning for several reasons:\n",
    "\n",
    "   1.They often lead to more accurate and robust predictions compared to single models.\n",
    "   \n",
    "   2.They can reduce overfitting by leveraging the diversity of different models.\n",
    "   \n",
    "   3.They are capable of handling complex relationships in data that may be difficult for individual models to capture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab3deeb",
   "metadata": {},
   "source": [
    "Q3. What is bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf36947",
   "metadata": {},
   "source": [
    "Ans:- Bagging (Bootstrap Aggregating) is an ensemble technique where multiple instances of the same base learning algorithm are trained on different subsets of the training data. Each subset is created through random sampling with replacement (bootstrap sampling). The predictions from these models are then combined (e.g., through averaging or voting) to make a final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1028797",
   "metadata": {},
   "source": [
    "Q4. What is boosting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200002df",
   "metadata": {},
   "source": [
    "Ans:- . Boosting is another ensemble technique where multiple weak learners (models that perform slightly better than random chance) are trained sequentially. Each new model focuses on the mistakes made by the previous ones. It assigns higher weights to misclassified data points, effectively giving more attention to the challenging instances. The final prediction is a weighted sum of the weak learners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1126ce",
   "metadata": {},
   "source": [
    "Q5. What are the benefits of using ensemble techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d23c4d",
   "metadata": {},
   "source": [
    "Ans:- Benefits of using ensemble techniques include:\n",
    "\n",
    "   1. Improved predictive performance and generalization.\n",
    "   2. Better handling of complex relationships in the data.\n",
    "   3. Reduction in overfitting and increased model robustness.\n",
    "   4. Capability to capture different aspects of the data due to diversity in models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e13630",
   "metadata": {},
   "source": [
    "Q6. Are ensemble techniques always better than individual models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ef7217",
   "metadata": {},
   "source": [
    "Ans:- Ensemble techniques are not always better than individual models. The effectiveness of ensembles depends on factors such as the quality and diversity of the base models, the nature of the data, and the specific problem being solved. In some cases, a well-tuned single model might perform just as well or even outperform an ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54c1794",
   "metadata": {},
   "source": [
    "Q7. How is the confidence interval calculated using bootstrap?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1258a2",
   "metadata": {},
   "source": [
    "Ans:- Confidence intervals using bootstrap are calculated by resampling the original data with replacement to create multiple bootstrap samples. For each sample, the statistic of interest (e.g., mean) is calculated. The confidence interval is then constructed using the percentiles of the bootstrap distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffa91a4",
   "metadata": {},
   "source": [
    "Q8. How does bootstrap work and What are the steps involved in bootstrap?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca4e981",
   "metadata": {},
   "source": [
    "Ans:- Bootstrap is a resampling method used to estimate the distribution of a statistic from a sample. Here are the steps involved in bootstrap:\n",
    "\n",
    "   1. Sample with Replacement: Draw a sample (called a bootstrap sample) of the same size as the original dataset, allowing for duplicates (sampling with replacement).\n",
    "   2. Compute Statistic: Calculate the statistic of interest (e.g., mean, standard deviation) on the bootstrap sample.\n",
    "   3. Repeat: Repeat steps 1 and 2 a large number of times (e.g., thousands of iterations) to create a distribution of the statistic.\n",
    "   4. Construct Confidence Interval: Use the percentiles of the bootstrap distribution to estimate the confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abff27b2",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to estimate the mean height of a population of trees. They measure the height of a\n",
    "sample of 50 trees and obtain a mean height of 15 meters and a standard deviation of 2 meters. Use\n",
    "bootstrap to estimate the 95% confidence interval for the population mean height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eaaa32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval for the Population Mean Height:\n",
      "Lower Bound: 14.45 meters\n",
      "Upper Bound: 15.56 meters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given data\n",
    "sample_mean = 15  # in meters\n",
    "sample_std_dev = 2  # in meters\n",
    "sample_size = 50\n",
    "num_bootstrap_samples = 10000\n",
    "\n",
    "# Step 1: Generate Bootstrap Samples\n",
    "bootstrap_means = []\n",
    "\n",
    "for _ in range(num_bootstrap_samples):\n",
    "    # Generate a bootstrap sample by randomly selecting with replacement\n",
    "    bootstrap_sample = np.random.normal(sample_mean, sample_std_dev, sample_size)\n",
    "    \n",
    "    # Calculate the mean of the bootstrap sample\n",
    "    bootstrap_mean = np.mean(bootstrap_sample)\n",
    "    bootstrap_means.append(bootstrap_mean)\n",
    "\n",
    "# Step 3: Calculate 95% Confidence Interval\n",
    "confidence_interval = np.percentile(bootstrap_means, [2.5, 97.5])\n",
    "\n",
    "print(\"95% Confidence Interval for the Population Mean Height:\")\n",
    "print(f\"Lower Bound: {confidence_interval[0]:.2f} meters\")\n",
    "print(f\"Upper Bound: {confidence_interval[1]:.2f} meters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499e8b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
